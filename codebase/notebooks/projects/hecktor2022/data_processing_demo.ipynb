{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from etils import epath\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torchio as tio\n",
    "from torchsummary import summary\n",
    "import plotly.express as px\n",
    "\n",
    "from codebase.preprocessor.images import multi_modal_processor\n",
    "from codebase.dataloader.images import multi_modal_dataloader\n",
    "import codebase.terminology as term\n",
    "import codebase.codebase_settings as cbs\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Preprossing data </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = cbs.CODEBASE_PATH / 'preprocessor' / 'images' / 'test_data'\n",
    "hecktor_processor_train = multi_modal_processor.MultiModalProcessor(\n",
    "    data_folder=data_folder, phase=term.Phase.TRAIN, modalities=[term.Modality.CT, term.Modality.PET],\n",
    "    reference=term.Modality.PET, problem_type=term.ProblemType.SEGMENTATION)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h> Original data </h>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = hecktor_processor_train.create_subject('CHUM-024')\n",
    "subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subject['CT'].shape)\n",
    "subject['CT'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subject['PT'].shape)\n",
    "subject['PT'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subject['LABEL'].shape)\n",
    "print(subject['LABEL'].data[1, ...].max())\n",
    "print(subject['LABEL'].data[2, ...].max())\n",
    "subject['LABEL'].plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h> Resample to reference (PET) </h>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_subject = hecktor_processor.resample_to_reference(subject=subject, xy_size=(128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resampled_subject['CT'].shape)\n",
    "print(resampled_subject['CT'].spacing)\n",
    "print(resampled_subject['PT'].spacing)\n",
    "print(resampled_subject['LABEL'].spacing)\n",
    "resampled_subject['CT'].plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h> Apply transformation: normalization and augmentation:\n",
    "\n",
    "CT: Clamp + Intensity rescale\n",
    "\n",
    "PET: Histogram Standardization + ZNormalization </h> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization = hecktor_processor.create_normalization()\n",
    "normalized_subject = normalization(resampled_subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_data = normalized_subject['CT'].numpy()\n",
    "print(f'max: {np.max(ct_data)}')\n",
    "print(f'min: {np.min(ct_data)}')\n",
    "normalized_subject['CT'].plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h> Process and save data </h>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = hecktor_processor.preprocess_and_save(xy_size=(128, 128), weight_modality=term.Modality.PET, weight_threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hecktor_processor_valid = multi_modal_processor.MultiModalProcessor(\n",
    "    data_folder=data_folder, phase=term.Phase.VALID, modalities=[term.Modality.CT, term.Modality.PET],\n",
    "    reference=term.Modality.PET, problem_type=term.ProblemType.SEGMENTATION)\n",
    "n = hecktor_processor_valid.preprocess_and_save(xy_size=(128, 128), weight_modality=term.Modality.PET, weight_threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_path = cbs.CODEBASE_PATH / 'preprocessor' / 'images' / 'test_data' / 'processed_128x128'\n",
    "hecktor_loader = multi_modal_dataloader.MultiModalDataLoader(data_folder=processed_data_path, phase=term.Phase.TRAIN,\n",
    "                                                             modalities=[term.Modality.CT, term.Modality.PET], problem_type=term.ProblemType.SEGMENTATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_subject = hecktor_loader.create_subject(patient='HGJ-080')\n",
    "processed_subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_subject['LABEL'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_subject['WEIGHT'].plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h> Data Augmentation </h>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_dict = {'flip': {'p': 1.0, 'axes': ('LR', 'AP')}}\n",
    "transformation = hecktor_loader.create_augmentation(transform_keys=transform_dict)\n",
    "final_subject = transformation(processed_subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_subject['CT'].plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h> Create dataset and dataloader </h>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = hecktor_loader.create_subject_list()\n",
    "subject_dataset = hecktor_loader.create_subject_dataset(subjects=subjects, augmentation=transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subjects[0].ID)\n",
    "print(subject_dataset[0].ID)\n",
    "subject_dataset[0].check_consistent_attribute('spacing')\n",
    "subjects[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = (128, 128, 32)\n",
    "sampler = tio.data.WeightedSampler(patch_size=patch_size, probability_map='WEIGHT')\n",
    "\n",
    "batch_size = 2\n",
    "num_workers = 1\n",
    "\n",
    "train_dataloader = hecktor_loader.create_patch_dataloader(\n",
    "    subject_dataset=subject_dataset,\n",
    "    max_queue_length=32,\n",
    "    samples_per_volume=4,\n",
    "    sampler=sampler,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['CT'][tio.DATA].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['LABEL'][tio.DATA].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_input = torch.cat([batch['CT'][tio.DATA], batch['PT'][tio.DATA]], dim=1)\n",
    "new_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_label = batch['LABEL'][tio.DATA][:, 1:, ...]\n",
    "print(new_label.shape)\n",
    "print(new_label[:, 0, ...].max())\n",
    "print(new_label[:, 1, ...].max())\n",
    "new_label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Subvolume generation </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hecktor_processor_train.create_and_save_subvolumes(data_path=data_folder / 'processed_128x128', \n",
    "                                             valid_channel=[1, 2], subvolume_intervel=4, subvolume_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.load(str(data_folder / 'processed_128x128/subvolume_32/train/images/CHUM-024_38__input.npy'))\n",
    "label = np.load(str(data_folder / 'processed_128x128/subvolume_32/train/labels/CHUM-024_38__label.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image.shape, label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_imgs = [label.data[0, :, :, :].numpy(), label.data[1, :, :, :].numpy(), label.data[2, :, :, :].numpy(),]\n",
    "all_imgs = np.swapaxes(image, 1, 3)\n",
    "px.imshow(\n",
    "    all_imgs,\n",
    "    # zmin=[0, 0, 0],\n",
    "    # zmax=[2000, 2000, 2000],\n",
    "    animation_frame=1,\n",
    "    # binary_string=gray_scale,\n",
    "    labels={'animation_frame': 'slice'},\n",
    "    facet_col=0,\n",
    "    color_continuous_scale='Gray',\n",
    "    width=500*3, height=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hecktor_processor_valid = multi_modal_processor.MultiModalProcessor(\n",
    "    data_folder=data_folder, phase=term.Phase.VALID, modalities=[term.Modality.CT, term.Modality.PET],\n",
    "    reference=term.Modality.PET, problem_type=term.ProblemType.SEGMENTATION)\n",
    "hecktor_processor_valid.create_and_save_subvolumes(data_path=data_folder / 'processed_128x128', \n",
    "                                             valid_channel=[1, 2], subvolume_intervel=4, subvolume_size=32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h> Check subvolume Dataloader </h>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader.images import subvolume_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_dict = {'flip': {'p': 0.5, 'axes': ('LR', 'AP')},\n",
    "                   # ration range has to consider whether the channel exist or not\n",
    "                   # because the transform assues no channels\n",
    "                   'rotate': {'radians': [0, 0.5, 0.5], 'p': 0.8},\n",
    "                   'affine': {'p': 0.5, 'degrees': 0.5, 'translation': 0.3}}\n",
    "print(data_folder)\n",
    "loader_processor_train = subvolume_dataloader.ProcessedSubVolumeDataLoader(data_folder=(data_folder / 'processed_128x128' / 'subvolume_32'),\n",
    "                                                           phase=term.Phase.TRAIN, batch_size=2, transform_dict=transform_dict,\n",
    "                                                           num_workders=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_processor_valid = subvolume_dataloader.ProcessedSubVolumeDataLoader(data_folder=(data_folder / 'processed_128x128' / 'subvolume_32'),\n",
    "                                                           phase=term.Phase.VALID, batch_size=2, transform_dict=transform_dict,\n",
    "                                                           num_workders=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = loader_processor_train.get_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = batch['label'][0, ...]\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['input'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'patient_stats.csv'\n",
    "columns = ['ID', 'GTVp volume', 'GTVn volume']\n",
    "hecktor_processor_train.calculate_volumes(data_path=data_folder / 'processed_128x128', output_file=filename, channels=[1, 2], column_names=columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h> Modeling debugging </h>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from projects.hecktor2022.trainers import hecktor_trainer\n",
    "\n",
    "config_file = cbs.CODEBASE_PATH / 'projects' / 'hecktor2022' / 'experiments' / 'test_config.yml'\n",
    "trainer = hecktor_trainer.Trainer(str(config_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, label = trainer.prepare_subvolume_batch(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features.shape, label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = label[0].cpu().numpy()\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = trainer.model(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = prediction[0].detach().cpu().numpy()\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = trainer.loss(prediction, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
