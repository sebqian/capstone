{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from etils import epath\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torchio as tio\n",
    "from torchsummary import summary\n",
    "import plotly.express as px\n",
    "\n",
    "from codebase.preprocessor.images import multi_modal_processor\n",
    "from codebase.dataloader.images import multi_modal_dataloader\n",
    "import codebase.terminology as term\n",
    "import codebase.codebase_settings as cbs\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Preprossing data </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = cbs.CODEBASE_PATH / 'preprocessor' / 'images' / 'test_data'\n",
    "hecktor_processor_train = multi_modal_processor.MultiModalProcessor(\n",
    "    data_folder=data_folder, phase=term.Phase.TRAIN, modalities=[term.Modality.CT, term.Modality.PET],\n",
    "    reference=term.Modality.CT, problem_type=term.ProblemType.SEGMENTATION)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h> Original data </h>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create raw subject\n",
    "subject = hecktor_processor_train.create_subject('MDA-103')\n",
    "subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subject['CT'].shape)\n",
    "subject['CT'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subject['PT'].shape)\n",
    "subject['PT'].plot()\n",
    "print(subject['PT'].data.max())\n",
    "print(subject['PT'].data.min())\n",
    "print(subject['PT'].data.mean())\n",
    "print(subject['PT'].data.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_data = subject['PT'].numpy().flatten()\n",
    "ax = plt.hist(pt_data[pt_data > 0.1], bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subject['LABEL'].shape)\n",
    "print(subject['LABEL'].data[1, ...].max())\n",
    "print(subject['LABEL'].data[2, ...].max())\n",
    "subject['LABEL'].plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h> Ignore: Apply histogram normalization to non-CT images </h>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_normalization = hecktor_processor_train.create_prior_normalization()\n",
    "prior_subject = prior_normalization(subject)\n",
    "landmarks = np.load(cbs.CODEBASE_PATH / 'preprocessor' / 'images' / 'test_data' / 'PT_landmarks.npy')\n",
    "print(landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_subject['PT'].plot()\n",
    "print(prior_subject['PT'].data.max())\n",
    "print(prior_subject['PT'].data.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_data = prior_subject['PT'].numpy().flatten()\n",
    "ax = plt.hist(pt_data[pt_data > 10], bins=100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h> Resample to reference (PET) </h>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_subject = hecktor_processor_train.resample_to_reference(subject=subject, xy_size=(512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resampled_subject['CT'].shape)\n",
    "print(resampled_subject['CT'].spacing)\n",
    "print(resampled_subject['PT'].spacing)\n",
    "print(resampled_subject['LABEL'].spacing)\n",
    "resampled_subject['CT'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_data = resampled_subject['PT'].numpy().flatten()\n",
    "ax = plt.hist(pt_data[pt_data > 0.1], bins=100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h> Create body mask </h>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_thresholds = {term.Modality.CT: (-300, 300), term.Modality.PET: (0.5, 9999)}\n",
    "resampled_subject = hecktor_processor_train.create_body_mask(resampled_subject, body_thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resampled_subject['BODY'].shape)\n",
    "resampled_subject['BODY'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(\n",
    "    np.swapaxes(resampled_subject['PT'].numpy(), 1, 3),\n",
    "    # zmin=[0, 0, 0],\n",
    "    # zmax=[2000, 2000, 2000],\n",
    "    animation_frame=1,\n",
    "    # binary_string=gray_scale,\n",
    "    labels={'animation_frame': 'slice'},\n",
    "    facet_col=0,\n",
    "    color_continuous_scale='Gray',\n",
    "    width=500, height=500\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h> Cropping the images </h>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_subject = hecktor_processor_train.find_bounding_box_and_crop(resampled_subject, desired_xy_size=(256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cropped_subject['CT'].shape)\n",
    "print(cropped_subject['CT'].spacing)\n",
    "cropped_subject['PT'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(cropped_subject['BODY'].tensor)[..., 150].sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h> Apply post_normalization:\n",
    "\n",
    "CT: Clamp + Intensity rescale\n",
    "\n",
    "PET: Normalize to brain </h> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_normalization = hecktor_processor_train.create_post_normalization()\n",
    "post_subject = post_normalization(cropped_subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_data = post_subject['CT'].numpy()\n",
    "print(f'max: {np.max(ct_data)}')\n",
    "print(f'min: {np.min(ct_data)}')\n",
    "post_subject['CT'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_data = post_subject['PT'].numpy()\n",
    "print(f'max: {np.max(pt_data)}')\n",
    "print(f'min: {np.min(pt_data)}')\n",
    "post_subject['PT'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(\n",
    "    np.swapaxes(pt_data, 1, 3),\n",
    "    # zmin=[0, 0, 0],\n",
    "    # zmax=[2000, 2000, 2000],\n",
    "    animation_frame=1,\n",
    "    # binary_string=gray_scale,\n",
    "    labels={'animation_frame': 'slice'},\n",
    "    facet_col=0,\n",
    "    color_continuous_scale='Gray',\n",
    "    width=500, height=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(pt_data.flatten(), bins=100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h> Process and save data </h>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = hecktor_processor_train.preprocess_and_save(xy_size=(256, 256), weight_modality=term.Modality.PET, weight_threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hecktor_processor_valid = multi_modal_processor.MultiModalProcessor(\n",
    "    data_folder=data_folder, phase=term.Phase.VALID, modalities=[term.Modality.CT, term.Modality.PET],\n",
    "    reference=term.Modality.CT, problem_type=term.ProblemType.SEGMENTATION)\n",
    "n = hecktor_processor_valid.preprocess_and_save(xy_size=(256, 256), weight_modality=term.Modality.PET, weight_threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_path = cbs.CODEBASE_PATH / 'preprocessor' / 'images' / 'test_data' / 'processed_128x128'\n",
    "hecktor_loader = multi_modal_dataloader.MultiModalDataLoader(data_folder=processed_data_path, phase=term.Phase.TRAIN,\n",
    "                                                             modalities=[term.Modality.CT, term.Modality.PET], problem_type=term.ProblemType.SEGMENTATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_subject = hecktor_loader.create_subject(patient='HGJ-080')\n",
    "processed_subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_subject['LABEL'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_subject['WEIGHT'].plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h> Data Augmentation </h>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_dict = {'flip': {'p': 1.0, 'axes': ('LR', 'AP')}}\n",
    "transformation = hecktor_loader.create_augmentation(transform_keys=transform_dict)\n",
    "final_subject = transformation(processed_subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_subject['CT'].plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h> Create dataset and dataloader </h>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = hecktor_loader.create_subject_list()\n",
    "subject_dataset = hecktor_loader.create_subject_dataset(subjects=subjects, augmentation=transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subjects[0].ID)\n",
    "print(subject_dataset[0].ID)\n",
    "subject_dataset[0].check_consistent_attribute('spacing')\n",
    "subjects[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = (128, 128, 32)\n",
    "sampler = tio.data.WeightedSampler(patch_size=patch_size, probability_map='WEIGHT')\n",
    "\n",
    "batch_size = 2\n",
    "num_workers = 1\n",
    "\n",
    "train_dataloader = hecktor_loader.create_patch_dataloader(\n",
    "    subject_dataset=subject_dataset,\n",
    "    max_queue_length=32,\n",
    "    samples_per_volume=4,\n",
    "    sampler=sampler,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['CT'][tio.DATA].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['LABEL'][tio.DATA].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_input = torch.cat([batch['CT'][tio.DATA], batch['PT'][tio.DATA]], dim=1)\n",
    "new_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_label = batch['LABEL'][tio.DATA][:, 1:, ...]\n",
    "print(new_label.shape)\n",
    "print(new_label[:, 0, ...].max())\n",
    "print(new_label[:, 1, ...].max())\n",
    "new_label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Subvolume generation </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hecktor_processor_train.create_and_save_subvolumes(data_path=data_folder / 'processed_256x256', \n",
    "                                             valid_channel=[0], subvolume_intervel=8, subvolume_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.load(str(data_folder / 'processed_256x256/subvolume_32/train/images/CHUP-052_34__input.npy'))\n",
    "label = np.load(str(data_folder / 'processed_256x256/subvolume_32/train/labels/CHUP-052_34__label.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image.shape, label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_imgs = [label.data[0, :, :, :].numpy(), label.data[1, :, :, :].numpy(), label.data[2, :, :, :].numpy(),]\n",
    "all_imgs = np.swapaxes(label, 1, 3)\n",
    "px.imshow(\n",
    "    all_imgs,\n",
    "    # zmin=[0, 0, 0],\n",
    "    # zmax=[2000, 2000, 2000],\n",
    "    animation_frame=1,\n",
    "    # binary_string=gray_scale,\n",
    "    labels={'animation_frame': 'slice'},\n",
    "    facet_col=0,\n",
    "    color_continuous_scale='Gray',\n",
    "    width=500, height=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hecktor_processor_valid = multi_modal_processor.MultiModalProcessor(\n",
    "    data_folder=data_folder, phase=term.Phase.VALID, modalities=[term.Modality.CT, term.Modality.PET],\n",
    "    reference=term.Modality.PET, problem_type=term.ProblemType.SEGMENTATION)\n",
    "hecktor_processor_valid.create_and_save_subvolumes(data_path=data_folder / 'processed_256x256', \n",
    "                                             valid_channel=[0], subvolume_intervel=8, subvolume_size=32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h> Check subvolume Dataloader </h>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader.images import subvolume_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_dict = {'flip': {'p': 0.5, 'axes': ('LR', 'AP')},\n",
    "                   # ration range has to consider whether the channel exist or not\n",
    "                   # because the transform assues no channels\n",
    "                   'rotate': {'radians': [0, 0.5, 0.5], 'p': 0.8},\n",
    "                   'affine': {'p': 0.5, 'degrees': 0.5, 'translation': 0.3}}\n",
    "print(data_folder)\n",
    "loader_processor_train = subvolume_dataloader.ProcessedSubVolumeDataLoader(data_folder=(data_folder / 'processed_128x128' / 'subvolume_32'),\n",
    "                                                           phase=term.Phase.TRAIN, batch_size=2, transform_dict=transform_dict,\n",
    "                                                           num_workders=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_processor_valid = subvolume_dataloader.ProcessedSubVolumeDataLoader(data_folder=(data_folder / 'processed_128x128' / 'subvolume_32'),\n",
    "                                                           phase=term.Phase.VALID, batch_size=2, transform_dict=transform_dict,\n",
    "                                                           num_workders=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = loader_processor_train.get_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = batch['label'][0, ...]\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['input'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'patient_stats.csv'\n",
    "columns = ['ID', 'GTVp volume', 'GTVn volume']\n",
    "hecktor_processor_train.calculate_volumes(data_path=data_folder / 'processed_128x128', output_file=filename, channels=[1, 2], column_names=columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h> Modeling debugging </h>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from projects.hecktor2022.trainers import hecktor_trainer\n",
    "\n",
    "config_file = cbs.CODEBASE_PATH / 'projects' / 'hecktor2022' / 'experiments' / 'test_config.yml'\n",
    "trainer = hecktor_trainer.Trainer(str(config_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, label = trainer.prepare_subvolume_batch(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features.shape, label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = label[0].cpu().numpy()\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = trainer.model(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = prediction[0].detach().cpu().numpy()\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = trainer.loss(prediction, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randrange(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = np.array([1, 2, 3])\n",
    "arr2 = np.array([4, 5, 6])\n",
    "np.multiply(arr1, arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
